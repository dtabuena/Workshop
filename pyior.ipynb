{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQbAYBBGV0XCQVIjztGMY1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Workshop/blob/main/pyior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64mDHqOyxmH6",
        "outputId": "60aba9ef-9a6f-4a22-ed8c-44a599e97c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  python setup.py bdist_wheel did not run successfully.\n",
            "  exit code: 1\n",
            "  \n",
            "  [37 lines of output]\n",
            "  C:\\Users\\dennis.tabuena\\AppData\\Local\\anaconda3\\envs\\notebook\\Lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "  !!\n",
            "  \n",
            "          ********************************************************************************\n",
            "          Requirements should be satisfied by a PEP 517 installer.\n",
            "          If you are using pip, you can try `pip install --use-pep517`.\n",
            "          ********************************************************************************\n",
            "  \n",
            "  !!\n",
            "    dist.fetch_build_eggs(dist.setup_requires)\n",
            "  WARNING setuptools_scm.pyproject_reading toml section missing 'pyproject.toml does not contain a tool.setuptools_scm section'\n",
            "  Traceback (most recent call last):\n",
            "    File \"c:\\users\\dennis.tabuena\\appdata\\local\\temp\\pip-install-t0vixp3w\\louvain_dd122aa6286441aabd2b27d15d3a4b29\\.eggs\\setuptools_scm-8.1.0-py3.12.egg\\setuptools_scm\\_integration\\pyproject_reading.py\", line 36, in read_pyproject\n",
            "      section = defn.get(\"tool\", {})[tool_name]\n",
            "                ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
            "  KeyError: 'setuptools_scm'\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build\\lib.win-amd64-cpython-312\n",
            "  creating build\\lib.win-amd64-cpython-312\\louvain\n",
            "  copying src\\louvain\\functions.py -> build\\lib.win-amd64-cpython-312\\louvain\n",
            "  copying src\\louvain\\Optimiser.py -> build\\lib.win-amd64-cpython-312\\louvain\n",
            "  copying src\\louvain\\version.py -> build\\lib.win-amd64-cpython-312\\louvain\n",
            "  copying src\\louvain\\VertexPartition.py -> build\\lib.win-amd64-cpython-312\\louvain\n",
            "  copying src\\louvain\\__init__.py -> build\\lib.win-amd64-cpython-312\\louvain\n",
            "  running build_ext\n",
            "  running build_c_core\n",
            "  We are going to build the C core of igraph.\n",
            "    Source folder: vendor\\source\\igraph\n",
            "    Build folder: vendor\\build\\igraph\n",
            "    Install folder: vendor\\install\\igraph\n",
            "  \n",
            "  igraph uses CMake as the build system. You need to install CMake before compiling igraph.\n",
            "  Build failed for the C core of igraph.\n",
            "  \n",
            "  [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for louvain\n",
            "ERROR: Could not build wheels for louvain, which is required to install pyproject.toml-based projects\n"
          ]
        }
      ],
      "source": [
        "!pip install scanpy --quiet\n",
        "!pip install pybiomart --quiet\n",
        "!pip install python-igraph --quiet\n",
        "!pip install louvain --quiet\n",
        "!pip install pynndescent --quiet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "from matplotlib import pyplot as plt\n",
        "import scanpy as sc\n",
        "import tarfile\n",
        "import os\n",
        "import anndata as ad\n",
        "import pandas as pd\n",
        "import pybiomart\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "from IPython.display import clear_output\n",
        "from matplotlib.pyplot import rc_context\n",
        "import logging\n",
        "import seaborn as sns\n",
        "# import gprofiler"
      ],
      "metadata": {
        "id": "WwYEB3fpxuk0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# SPECIFIC CONFIG #############\n",
        "working_dir = r\"C:\\Users\\dennis.tabuena\\Gladstone Dropbox\\Dennis Tabuena\\0_Projects\\_pyior\"\n",
        "os.makedirs(working_dir,exist_ok=True)\n",
        "os.chdir(working_dir)\n",
        "zalocusky_url = 'https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE167497&format=file'\n",
        "geo_zalo_filename = 'zalocusky_indiv.tar'\n",
        "\n",
        "import urllib\n",
        "response = urllib.request.urlretrieve('https://raw.githubusercontent.com/dtabuena/Resources/main/Matplotlib_Config/Load_FS6.py','Load_FS6.py')\n",
        "%run Load_FS6.py\n",
        "\n"
      ],
      "metadata": {
        "id": "GxNhhZ8IxwMl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_key(k):\n",
        "    floxed_dict = {'GSM5106175_YH_KZ03_01':('E3fKI_Syn_Cre602_15m','GSM5106175_602_E3fKI_15_XX'),\n",
        "                   'GSM5106176_YH_KZ03_03':('E4fKI_Syn_Cre475_15m','GSM5106176_475_E4fKI_15_XX')}\n",
        "    for f in floxed_dict.keys():\n",
        "        if f in k: return floxed_dict[f][1]\n",
        "    k = k.replace('_raw_gene_bc_matrices_h5.h5',\"\")\n",
        "    return k\n",
        "\n",
        "def query_capitilaziation(gene,adata):\n",
        "    try:\n",
        "        return adata.var.index[ [g.lower() for g in list(adata.var.index)].index(gene.lower()) ]\n",
        "    except:\n",
        "        return gene + ' not_found'\n",
        "\n",
        "def z_score(x,axis=-1):\n",
        "    x=np.array(x)\n",
        "    return (x-np.mean(x,axis=axis))/np.std(x,axis=axis)\n",
        "\n"
      ],
      "metadata": {
        "id": "LmMAhbhKyIO8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_gene_annots(csv_loc='./mmusculus_coding_noncoding.csv',\n",
        "                     my_git='https://raw.githubusercontent.com/dtabuena/Resources/main/Genetics/mmusculus_coding_noncoding.csv',\n",
        "                     biomart_name='mmusculus',\n",
        "                     biomart_keys=[\"ensembl_gene_id\", \"chromosome_name\",\"transcript_biotype\",\"external_gene_name\",\"peptide\"]):\n",
        "\n",
        "    if os.path.exists('./mmusculus_coding_noncoding.csv'):\n",
        "        print( 'Use local copy of musmus')\n",
        "        annot_dd = pd.read_csv('./mmusculus_coding_noncoding.csv').set_index(\"external_gene_name\")\n",
        "    else:\n",
        "        try:\n",
        "            print( 'attempting to pull mus mus from git...')\n",
        "            musmus_link = 'https://raw.githubusercontent.com/dtabuena/Resources/main/Genetics/mmusculus_coding_noncoding.csv'\n",
        "            filename = './mmusculus_coding_noncoding.csv'\n",
        "            urllib.request.urlretrieve(musmus_link, filename)\n",
        "            annot_dd = pd.read_csv('./mmusculus_coding_noncoding.csv').set_index(\"external_gene_name\")\n",
        "        except:\n",
        "            print('attempting to pull mus mus from biomart...')\n",
        "            annot = sc.queries.biomart_annotations(\"mmusculus\",[\"ensembl_gene_id\", \"chromosome_name\",\"transcript_biotype\",\"external_gene_name\"],).set_index('ensembl_gene_id')\n",
        "            uniq_inds = list(set(list(annot.index)))\n",
        "            for r in tqdm(uniq_inds):\n",
        "                match_bool = annot.index.str.contains(r)\n",
        "                if np.sum(match_bool)>1:\n",
        "                    new_val ='__'.join(list(annot.loc[r,'transcript_biotype']))\n",
        "                    annot.at[r,'transcript_biotype']=new_val\n",
        "            annot['is_coding']= annot.transcript_biotype.str.contains('coding')\n",
        "            annot_dd = annot.drop_duplicates().set_index(\"external_gene_name\")\n",
        "            annot_dd.to_csv('./mmusculus_coding_noncoding.csv')\n",
        "\n",
        "    coding_list = annot_dd.index[ annot_dd['is_coding'] ].to_list()\n",
        "    return coding_list, annot_dd\n",
        "\n",
        "\n",
        "def preprocess_andata10x(adata_og,pct_mito=0.25,min_genes=500,max_genes=2400,min_counts=500,max_counts=4500,keep_NC=False):\n",
        "\n",
        "    print('pulling gene annotations...')\n",
        "    coding_list, _ = pull_gene_annots()\n",
        "    adata_og.var['mt'] = adata_og.var_names.str.startswith('mt-')\n",
        "    adata_og.var['coding'] = [gene in coding_list for gene in adata_og.var_names]\n",
        "    sc.pp.calculate_qc_metrics(adata_og, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
        "\n",
        "    adata_QC = adata_og.copy()\n",
        "\n",
        "    print('Filtering...')\n",
        "    adata_QC = adata_QC[adata_QC.obs.pct_counts_mt < pct_mito, :]\n",
        "    print(str(np.sum(adata_og.obs.pct_counts_mt <pct_mito)) + f' cells with >{pct_mito}% mt removed')\n",
        "\n",
        "    if keep_NC:\n",
        "        print('keep noncoding')\n",
        "    else:\n",
        "        adata_QC = adata_QC[:, adata_QC.var.coding]\n",
        "        print(str(np.sum(np.logical_not(adata_og.var.coding))) + ' non coding genes removed')\n",
        "\n",
        "    sc.pp.filter_cells(adata_QC, min_genes=min_genes)\n",
        "    sc.pp.filter_cells(adata_QC, max_genes=max_genes)\n",
        "    sc.pp.filter_cells(adata_QC, min_counts=min_counts)\n",
        "    sc.pp.filter_cells(adata_QC, max_counts=max_counts)\n",
        "    fig,ax=plt.subplots(1,figsize=(1.5,1.5))\n",
        "    sc.pl.scatter(adata_QC, x='total_counts', y='n_genes_by_counts',ax=ax)\n",
        "\n",
        "    return adata_QC,adata_og\n",
        "\n",
        "def high_var_genes_dim_reduc(adata,min_mean = 0.25,max_mean = 4,min_disp=0.55):\n",
        "    ''' The gene expression matrices were then log-normalized with a scale factor of 10,000,\n",
        "    using the Seurat NormalizeData function57,58. Highly dispersed genes were selected using\n",
        "    the Seurat FindVariableGenes function57,58,filtering for an average expression range of\n",
        "    0.25–4 and a minimum dispersion of 0.55, resulting in a list of 2,197 genes.'''\n",
        "    adata.raw = adata\n",
        "    sc.pp.normalize_total(adata, target_sum=10000)\n",
        "    sc.pp.log1p(adata)\n",
        "    adata.uns['log1p'] = {'base': None}\n",
        "    print(adata.uns['log1p'])\n",
        "    sc.pp.highly_variable_genes(adata, min_mean=min_mean, max_mean=max_mean, min_disp=min_disp)\n",
        "    with rc_context({'figure.figsize': (1.5, 1.5)}):\n",
        "        sc.pl.highly_variable_genes(adata)\n",
        "    plt.tight_layout()\n",
        "    print(np.sum(adata.var['highly_variable']),'hv genes')\n",
        "\n",
        "\n",
        "    #### PCA\n",
        "    sc.tl.pca(adata, svd_solver='arpack',n_comps=50)\n",
        "    fig,ax=plt.subplots(figsize=(1,1))\n",
        "    ax.plot(adata.uns['pca']['variance_ratio'][:25],'ok',markersize=1)\n",
        "    quiet_PCA_plots(adata,['E_type','age_bin','mouse_ID'],pc_pairs=[(0,1),(2,3)])\n",
        "\n",
        "    return adata\n",
        "\n",
        "def quiet_PCA_plots(adata,key_list,figsize=(2,2),pc_pairs=[(0,1)]):\n",
        "    fig,ax=plt.subplots(1*len(pc_pairs),len(key_list),figsize=(figsize[0]*len(key_list),figsize[1]*len(pc_pairs)))\n",
        "    for ip,pair in enumerate(pc_pairs):\n",
        "        if len(key_list) == 1: ax=[ax]\n",
        "        for key_ind,key in enumerate(key_list):\n",
        "            key_types = sorted(list(set( adata.obs[key] )))\n",
        "            for k in key_types:\n",
        "                is_k = adata.obs[key]==k\n",
        "                ax[ip,key_ind].scatter(adata.obsm['X_pca'][is_k,pair[0]],adata.obsm['X_pca'][is_k,pair[1]],s=2,marker='.',linewidth=0,edgecolors=None,label=k)\n",
        "                ax[ip,key_ind].set_xlabel(f'PC{pair[0]}')\n",
        "                ax[ip,key_ind].set_ylabel(f'PC{pair[1]}')\n",
        "            if len(key_types)<8: ax[ip,key_ind].legend(key_types,loc='best',markerscale=3)\n",
        "            ax[ip,key_ind].set_title(key)\n",
        "            plt.tight_layout()\n",
        "    return None\n",
        "\n",
        "\n",
        "def umap_and_cluster(adata, n_neighbors=10, n_pcs=20,resolution=.6,plot_keys=['Cluster (nn)'],size = 1,to_plot=True):\n",
        "    sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=n_pcs,random_state=42, use_rep='X_pca')\n",
        "    sc.tl.louvain(adata,resolution=resolution,random_state=42)\n",
        "    sc.tl.paga(adata)\n",
        "    sc.tl.umap(adata,random_state=42)\n",
        "    adata.obs['Cluster (nn)']= adata.obs['louvain']\n",
        "    if to_plot:\n",
        "        with rc_context({'figure.figsize': (2.5, 2.5)}):\n",
        "            sc.pl.umap(adata,add_outline=False, legend_loc='on data', color=plot_keys,size=size)\n",
        "    return adata\n",
        "\n",
        "def explore_umap(adata_GABA,key_list=[],size=1,legend_loc=None):\n",
        "    with rc_context({'figure.figsize': (1.5,1.5)}):\n",
        "        sc.pl.umap(adata_GABA, legend_loc=legend_loc, color=key_list,vmin=-0.5,size=size,cmap='Purples') # add_outline=True,\n",
        "        plt.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "yQtaCmSfyKT9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################# INITIALIZE DIRECTORY DOWNLOAD FROM GEO\n",
        "os.chdir(working_dir)\n",
        "os.makedirs('./indiv_animal_results', exist_ok=True)\n",
        "urllib.request.urlretrieve(zalocusky_url, './indiv_animal_results/'+geo_zalo_filename)\n",
        "my_tar = tarfile.open('./indiv_animal_results/'+geo_zalo_filename)\n",
        "my_tar.extractall('./indiv_animal_results') # specify which folder to extract to\n",
        "my_tar.close()\n",
        "# for f in os.listdir('./indiv_animal_results'):\n",
        "#     print(f)\n"
      ],
      "metadata": {
        "id": "dAzeNtwOyMIU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################# Read, Combine, and Sample Split multiple 10x's\n",
        "\n",
        "adata_dict = {}\n",
        "for f in os.listdir('./indiv_animal_results'):\n",
        "    if '.h5' in f:\n",
        "        a = sc.read_10x_h5('./indiv_animal_results/'+f)\n",
        "        a.var_names_make_unique()\n",
        "        sample_code = trim_key(f)\n",
        "        a.obs['age_bin'] = str(int(np.ceil( int(sample_code.split(\"_\")[3])/5)*5))+'m'\n",
        "        a.obs['E_type'] = sample_code.split(\"_\")[2]\n",
        "        a.obs['mouse_ID'] = sample_code.split(\"_\")[1]\n",
        "        a.obs['well'] = sample_code.split(\"_\")[4]\n",
        "        a.obs['GSM'] = sample_code.split(\"_\")[0]\n",
        "        adata_dict[sample_code.split(\"_\")[0]] = a\n",
        "adata = ad.concat(adata_dict,axis = 0,label=\"Sample\",index_unique=\"_\")\n",
        "adata.obs.E_type\n",
        "# adata = adata[['fKI' not in t for t in adata.obs.E_type], :]\n",
        "adata_dict = {}\n",
        "clear_output()\n",
        "adata.write_h5ad(filename='./kz_adata_raw.h5')\n",
        "\n",
        "\n",
        "adata_QC = preprocess_andata10x(adata,keep_NC=True)[0]\n",
        "adata_QC.write_h5ad(filename='./kz_adata_qc.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFQigvwpyS6E",
        "outputId": "debeeabf-94a5-4f9d-e94e-b0cd1d850c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pulling gene annotations...\n",
            "attempting to pull mus mus from git...\n",
            "Filtering...\n",
            "14987892 cells with >0.25% mt removed\n",
            "keep noncoding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\dennis.tabuena\\AppData\\Local\\anaconda3\\envs\\notebook\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
            "  adata.obs[\"n_genes\"] = number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############## QC Filter #####################\n",
        "adata_full = adata_QC.copy()\n",
        "age_dict = {'5m':'05m', '10m': '10m','15m': '15m','20m': '20m'}\n",
        "adata_full.obs['age_bin'] = [ age_dict[a] for a in adata_full.obs['age_bin'] ]\n",
        "\n",
        "sc.pp.filter_genes(adata_full, min_counts=50)\n",
        "\n",
        "############## Dim Reduction #####################\n",
        "adata_full = high_var_genes_dim_reduc(adata_full)\n",
        "adata_full.write_h5ad(filename='./adata_full.h5')\n",
        "print(adata_full.uns['log1p'])\n"
      ],
      "metadata": {
        "id": "iwojZejvyhsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############## Dim Reduction #####################\n",
        "adata_full = ad.read_h5ad('./adata_full.h5')"
      ],
      "metadata": {
        "id": "QlSGeVJ_ykcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_GHBfP0T0Ixs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
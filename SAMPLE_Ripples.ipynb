{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Workshop/blob/main/SAMPLE_Ripples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxSyipyiImED"
      },
      "outputs": [],
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "from google import colab\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "clear_output(wait=False)\n",
        "\n",
        "\n",
        "\n",
        "!pip install openpyxl\n",
        "!pip install XlsxWriter\n",
        "!pip install --upgrade pyabf\n",
        "import pyabf\n",
        "\n",
        "\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_drobox_folder(link, new_filename):\n",
        "    'Download a folder from dropbox and unzip'\n",
        "    zipped_file_path = \"/content/\"+new_filename + \".zip\"\n",
        "    unzipped_file_path = \"/content/\"+new_filename\n",
        "    if not( os.path.exists(zipped_file_path)):\n",
        "        !wget -O $zipped_file_path $link    # download with new name\n",
        "    # if not( os.path.exists(new_filename_stripped)):\n",
        "    !echo A | unzip $zipped_file_path -d $unzipped_file_path\n",
        "    return new_filename\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_source = \"https://www.dropbox.com/sh/cz03im6sa98nquz/AAB-WXnlE4jdTp37CiwVPUCLa?dl=0\"\n",
        "data_name = 'rip_data'\n",
        "file_loc = get_drobox_folder(data_source, data_name)\n",
        "file_list = []\n",
        "for (root, dirs, file) in os.walk(file_loc):\n",
        "    for f in file:\n",
        "        if \".abf\" in f:\n",
        "            file_list.append(os.path.join(root,f))\n",
        "\n",
        "\n",
        "clear_output()\n"
      ],
      "metadata": {
        "id": "LSrhjkWmJU8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### MATH\n",
        "def z_trans_2(x):\n",
        "    x_mean = np.expand_dims(np.mean(x,axis=1),1)\n",
        "    x_std = np.expand_dims(np.std(x,axis=1),1)\n",
        "    x_z = (x - x_mean) / x_std\n",
        "    return x_z\n",
        "\n",
        "def z_trans(x):\n",
        "    x_mean = np.mean(x)\n",
        "    x_std = np.std(x)\n",
        "    x_z = (x - x_mean) / x_std\n",
        "    return x_z\n",
        "\n",
        "def mov_mean(x,stride):\n",
        "    x_mm = np.convolve(x,np.ones(stride),'same')/stride\n",
        "    return x_mm"
      ],
      "metadata": {
        "id": "ej60vO0_7ukM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_trace(trace,time,line_length=10,start_stop=[],z_scale=3,single_trace_plot_size=[30,2],figax_prev=False,spec_color=False):\n",
        "    ''' waterfall plot of trace '''\n",
        "    if len(start_stop) <2: start_stop=[time[0],time[-1]]\n",
        "    fs = 1/(time[1]-time[0])\n",
        "    max_t_adj =  np.ceil(start_stop[1]/line_length)*line_length\n",
        "    pad_width =  int(fs*(max_t_adj) - len(time))\n",
        "    pad_trace = np.pad(trace,((0,pad_width)),constant_values=(np.nan,np.nan))\n",
        "    pad_time =  np.pad(time,pad_width,'constant',constant_values=(np.nan,np.nan))\n",
        "\n",
        "    tics_per_line = int(fs*line_length)\n",
        "    num_lines = int(len(time)/tics_per_line)+1\n",
        "    pad_trace_stack = np.reshape(pad_trace,[num_lines,tics_per_line])\n",
        "\n",
        "    line_time = np.arange(tics_per_line)/fs\n",
        "    line_time_stack = np.resize(line_time,[num_lines,tics_per_line] )\n",
        "\n",
        "\n",
        "\n",
        "    y_adjust_const = np.std(trace)*z_scale\n",
        "    y_adj = y_adjust_const * (np.cumsum(np.ones_like(pad_trace_stack)*-1,axis=0)+1)\n",
        "\n",
        "    if not figax_prev:\n",
        "        plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", np.flip(plt.cm.viridis(np.linspace(0,1,10)),axis=0))\n",
        "        fig,ax=plt.subplots(figsize=(single_trace_plot_size[0],single_trace_plot_size[1]*num_lines))\n",
        "    else: (fig,ax) = figax_prev\n",
        "\n",
        "    if not spec_color: ax.plot(line_time_stack.T,(pad_trace_stack+y_adj).T)\n",
        "    else: ax.plot(line_time_stack.T,(pad_trace_stack+y_adj).T,color = spec_color)\n",
        "\n",
        "\n",
        "\n",
        "    from matplotlib.ticker import MultipleLocator\n",
        "    ax.yaxis.set_minor_locator(MultipleLocator(z_scale/2))\n",
        "\n",
        "    return fig,ax\n",
        "\n"
      ],
      "metadata": {
        "id": "RMQ7CC_4ESet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []\n",
        "\n",
        "dates_to_analyze = ['2023x07x06','2023x07x07_E3KI','2023x07x13','2023x07x12','2023x07x14','2023x07x17']\n",
        "for (rt,dr,files) in os.walk('/content/rip_data/'):\n",
        "    for f in files:\n",
        "        for d in dates_to_analyze:\n",
        "            if d in f and '.abf' in f[-4:]:\n",
        "                file_list.append(os.path.join(rt,f))\n",
        "\n",
        "file_list.sort()\n",
        "clear_output()\n",
        "print(len(file_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wY29qtmAv8m",
        "outputId": "9093e350-e3e5-4008-f18b-3f6d306ba5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Match Recs and Notes\n",
        "rip_notes = pd.read_csv('/content/rip_data/Ripples - Sheet1.csv') # .set_index('Slice_Code')\n",
        "keep_rows = []\n",
        "for r in rip_notes.index:\n",
        "    sl = str(rip_notes.loc[r,'Slice_Code'])\n",
        "    check_slice = any([sl in f for f in file_list])\n",
        "    if check_slice: keep_rows.append(True)\n",
        "    else: keep_rows.append(False)\n",
        "rip_notes = rip_notes[keep_rows]\n",
        "\n",
        "\n",
        "for r in rip_notes.index:\n",
        "    sl = rip_notes.loc[r,'Slice_Code']\n",
        "    number =rip_notes.loc[r,'rec']\n",
        "    if not np.isnan(number):    rec_str = f\"{int(number):04d}\"\n",
        "    else:    rec_str = 'nan'\n",
        "    slice_code_plus = sl+ '_' + rec_str\n",
        "    rip_notes.at[r,'slice_code_plus']=slice_code_plus\n",
        "rip_notes = rip_notes.set_index('slice_code_plus')\n",
        "\n",
        "\n",
        "\n",
        "rip_df = pd.DataFrame(index=file_list)\n",
        "\n",
        "chan_list = ['ch_0','ch_1']\n",
        "for c in chan_list:\n",
        "    rip_df[c]=np.nan\n",
        "    rip_df[c] = rip_df[c].astype('object')\n",
        "\n",
        "\n",
        "\n",
        "for f in rip_df.index:\n",
        "    f_slice = os.path.basename(f)[:-4]\n",
        "    if f_slice in rip_notes.index:\n",
        "        # print(f_slice)\n",
        "        # print(rip_notes.loc[f_slice,'epoch_0'])\n",
        "        rip_df.at[f,'epoch_0'] = rip_notes.loc[f_slice,'epoch_0']\n",
        "        rip_df.at[f,'epoch_1'] = rip_notes.loc[f_slice,'epoch_1']\n",
        "\n",
        "\n",
        "rip_df_keep = []\n",
        "for f in rip_df.index:\n",
        "    f_slice = os.path.basename(f)[:-4]\n",
        "    rip_df_keep.append(f_slice in rip_notes.index)\n",
        "rip_df=rip_df[rip_df_keep]\n",
        "\n",
        "\n",
        "### convert to HDF\n",
        "for f in rip_df.index:\n",
        "    row_series = (rip_df.loc[f]).to_frame().transpose()\n",
        "    hdf_fold = '/content/hdf_files'\n",
        "    try: os.makedirs(hdf_fold)\n",
        "    except: None\n",
        "    key_f = f.replace('/',\"\")\n",
        "    hdf_path = hdf_fold+'/'+os.path.basename(f)[:-4] +'.h5'\n",
        "    row_series.to_hdf(hdf_path,key=key_f)\n",
        "\n",
        "# def get_keys(data_name='LFP_Data.h5'):\n",
        "#     hf = h5py.File('LFP_Data.h5', 'r')\n",
        "#     hf_keys = list(hf.keys())\n",
        "#     hf.close()\n",
        "#     return hf_keys\n",
        "# print( get_keys() )"
      ],
      "metadata": {
        "id": "06jb7PShixkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_bands(abf,sweepNumber=0,channel=0,order = 4,blank_time=4):\n",
        "    fs = abf.sampleRate\n",
        "    abf.setSweep(sweepNumber=sweepNumber,channel=channel)\n",
        "    v_trace = abf.sweepY\n",
        "    time = abf.sweepX\n",
        "\n",
        "    new_fs = 1000\n",
        "    ds_factor = np.ceil(fs/new_fs)\n",
        "    v_trace_1khz = v_trace[::int(ds_factor)]\n",
        "    time_1khz = time[::int(ds_factor)]\n",
        "\n",
        "    v_trace_1khz[np.arange(0,blank_time*fs)] = v_trace_1khz[blank_time*fs]\n",
        "\n",
        "    b, a = scipy.signal.butter(order, [0.7,300], btype='bandpass',fs=new_fs)\n",
        "    wide_band = scipy.signal.filtfilt(b, a, v_trace_1khz)\n",
        "\n",
        "    b, a = scipy.signal.butter(order, [150,250], btype='bandpass',fs=new_fs)\n",
        "    ripple_band = scipy.signal.filtfilt(b, a, wide_band)\n",
        "\n",
        "    b, a = scipy.signal.butter(order, [15 ,50], btype='bandpass',fs=new_fs)\n",
        "    slow_gamma_band = scipy.signal.filtfilt(b, a, wide_band)\n",
        "\n",
        "    b, a = scipy.signal.butter(order, [1 ,20], btype='bandpass',fs=new_fs)\n",
        "    sharp_wave_band = scipy.signal.filtfilt(b, a, wide_band)\n",
        "\n",
        "    freq_bands = {'fs':new_fs,\n",
        "                  'time_1khz':time_1khz,\n",
        "                  'wide_band':wide_band,\n",
        "                  'sharp_wave_band':sharp_wave_band,\n",
        "                  'ripple_band':ripple_band,\n",
        "                  'slow_gamma_band':slow_gamma_band,\n",
        "                  }\n",
        "\n",
        "    for k in freq_bands.keys():\n",
        "        if 'band' in k:\n",
        "            freq_bands[k] = {'lfp': freq_bands[k]}\n",
        "        # if 'band' in k:\n",
        "        #         amplitude_envelope = np.abs(scipy.signal.hilbert(freq_bands[k]))\n",
        "        #         amplitude_envelope[np.arange(0,blank_time*fs)] = amplitude_envelope[blank_time*fs]\n",
        "        #         freq_bands[k] = {'lfp': freq_bands[k], 'hilb_env':amplitude_envelope}\n",
        "\n",
        "    return freq_bands\n",
        "\n",
        "\n",
        "\n",
        "for f in tqdm( rip_df.index ):\n",
        "    key_f = f.replace('/',\"\")\n",
        "    hdf_path = hdf_fold+'/'+os.path.basename(f)[:-4] +'.h5' # rec_entry.to_hdf(hdf_path,key=key_f)\n",
        "    rec_entry = pd.read_hdf(hdf_path,key=key_f)\n",
        "    abf = pyabf.ABF(f)\n",
        "    blank_time=5\n",
        "    rec_entry.at[f,'ch_0'] = time_bands(abf,sweepNumber=0,channel=0,blank_time=blank_time)\n",
        "    rec_entry.at[f,'ch_1'] = time_bands(abf,sweepNumber=0,channel=1,blank_time=blank_time)\n",
        "    rec_entry.to_hdf(hdf_path,key=key_f)\n"
      ],
      "metadata": {
        "id": "UnGhJllWgSBF",
        "outputId": "b77ffc17-0d0f-4a27-cd5e-6e715309743f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:52<00:00,  1.74s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zip_and_dl(folder):\n",
        "    zip_name = folder+'.zip'\n",
        "    !zip -r $zip_name $folder\n",
        "    colab.files.download(zip_name)\n",
        "# zip_and_dl('/content/hdf_files')"
      ],
      "metadata": {
        "id": "6UXAczxHZpub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Parse Epochs \"\"\"\n",
        "for f in tqdm( rip_df.index ):\n",
        "    key_f = f.replace('/',\"\")\n",
        "    hdf_path = hdf_fold+'/'+os.path.basename(f)[:-4]+'.h5'\n",
        "    rec_entry = pd.read_hdf(hdf_path,key=key_f)\n",
        "\n",
        "\n",
        "    epoch_list = ['ep_0_inds','ep_1_inds']\n",
        "    for e in epoch_list:\n",
        "        rec_entry[e] = np.nan\n",
        "        rec_entry[e] = rec_entry[e].astype('object')\n",
        "\n",
        "    epoch_0_tag = rec_entry.loc[f,'epoch_0']\n",
        "    epoch_0_time = epoch_0_tag.split(' ')[1]\n",
        "\n",
        "    if ':' in epoch_0_time: int(epoch_0_time.split(':')[0]*60 + epoch_0_time.split(':')[1] ) #mm:ss > sss\n",
        "\n",
        "    epoch_1_tag = rec_entry.loc[f,'epoch_1']\n",
        "    if isinstance(epoch_1_tag,str):\n",
        "        epoch_1_time = epoch_1_tag.split(' ')[1]\n",
        "        if ':' in epoch_1_time: epoch_1_time =  int( epoch_1_time.split(':')[0])*60 + int(epoch_1_time.split(':')[1] )\n",
        "    else:\n",
        "        epoch_1_time = np.nan\n",
        "\n",
        "    # epoch indicies\n",
        "    fs = rec_entry.loc[f,'ch_0']['fs']\n",
        "    time = rec_entry.at[f,'ch_0']['time_1khz']\n",
        "    if np.isnan(epoch_1_time):\n",
        "        rec_entry.at[f,'ep_0_inds'] = np.arange(0,len(time))\n",
        "    else:\n",
        "        rec_entry.at[f,'ep_0_inds'] = np.arange(0, epoch_1_time*fs)\n",
        "        rec_entry.at[f,'ep_1_inds'] = np.arange(epoch_1_time*fs,len(time))\n",
        "\n",
        "    rec_entry.to_hdf(hdf_path,key=key_f)\n"
      ],
      "metadata": {
        "id": "LIaF3JifrDK6",
        "outputId": "9907c0cf-b9ba-45d6-a783-0abadb8bfe8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:30<00:00,  1.02s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_and_dl('/content/hdf_files')"
      ],
      "metadata": {
        "id": "1jlk2qynZzJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def triggered_inds(trace,fs,sd_thresh= 3,min_dur_ms= 5,peak_wind_ms=20):\n",
        "    ''' trigger on crossing'''\n",
        "    trig_bool = z_trans(trace)>sd_thresh\n",
        "    min_dur_tic = int(min_dur_ms*fs/1000)\n",
        "    trig_bool = mov_mean(trig_bool,min_dur_tic)==1\n",
        "    trigs = np.arange(len(trig_bool))[np.diff(trig_bool,prepend=0)==1]\n",
        "\n",
        "    ''' allign peaks'''\n",
        "    tick_range = peak_wind_ms/1000*fs\n",
        "    peak_window_tics = np.arange(0,tick_range,dtype=int)\n",
        "    trig_alligned = []\n",
        "    max_tick = len(trace)\n",
        "    for t in trigs:\n",
        "        if (t+peak_window_tics[0])>=0 and (t+peak_window_tics[-1])<max_tick:\n",
        "            sub_trace = trace[t+peak_window_tics]\n",
        "            peak_tick = np.where(sub_trace==np.max(sub_trace))[0][0]\n",
        "            trig_alligned.append(t+peak_tick-np.min(peak_window_tics))\n",
        "    trig_alligned=np.array(trig_alligned)\n",
        "\n",
        "    return trig_alligned\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trig_bands = ['ripple_band','sharp_wave_band','slow_gamma_band']\n",
        "\n",
        "for f in tqdm( rip_df.index ):\n",
        "    key_f = f.replace('/',\"\")\n",
        "    hdf_path = hdf_fold+'/'+os.path.basename(f)[:-4]+'.h5'\n",
        "    rec_entry = pd.read_hdf(hdf_path,key=key_f)\n",
        "\n",
        "    for ch in chan_list:\n",
        "        filtered = rec_entry.loc[f,ch]\n",
        "        for b in trig_bands:\n",
        "            amplitude_envelope = np.abs(scipy.signal.hilbert(filtered[b]['lfp']))\n",
        "            amplitude_envelope[np.arange(0,blank_time*fs)] = amplitude_envelope[blank_time*fs]\n",
        "            trace = amplitude_envelope\n",
        "            fs = filtered['fs']\n",
        "            trigs = triggered_inds(trace,fs)\n",
        "            filtered[b]['trigs'] = trigs\n",
        "            # print(len(trigs))\n",
        "        rec_entry.at[f,ch] =filtered\n",
        "        rec_entry.to_hdf(hdf_path,key=key_f)\n",
        "\n",
        "\n",
        "\n",
        "IIS_bands = ['wide_band']\n",
        "for f in tqdm( rip_df.index ):\n",
        "    key_f = f.replace('/',\"\")\n",
        "    hdf_path = hdf_fold+'/'+os.path.basename(f)[:-4]+'.h5'\n",
        "    rec_entry = pd.read_hdf(hdf_path,key=key_f)\n",
        "    for ch in chan_list:\n",
        "        filtered = rec_entry.loc[f,ch]\n",
        "        for b in IIS_bands:\n",
        "            amplitude_envelope = np.abs(scipy.signal.hilbert(filtered[b]['lfp']))\n",
        "            amplitude_envelope[np.arange(0,blank_time*fs)] = amplitude_envelope[blank_time*fs]\n",
        "            trace = amplitude_envelope\n",
        "            fs = filtered['fs']\n",
        "            trigs = triggered_inds(trace,fs,sd_thresh = 15)\n",
        "            filtered[b]['trigs'] = trigs\n",
        "            # print(len(trigs))\n",
        "        rec_entry.at[f,ch] =filtered\n",
        "        rec_entry.to_hdf(hdf_path,key=key_f)\n"
      ],
      "metadata": {
        "id": "wmCXzA9CxiJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c879e33-ca47-4dde-97f0-70db6747cd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [02:32<00:00,  5.10s/it]\n",
            "100%|██████████| 30/30 [01:31<00:00,  3.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_waveforms_stack(waveform,trigs,fs,window_ms=[-150,150]):\n",
        "    window_s = np.array(window_ms)/fs\n",
        "    window_tics = np.arange(window_ms[0]/1000*fs,window_ms[1]/1000*fs,1,dtype=int)\n",
        "    window_time = window_tics/fs\n",
        "    wave_snip_list = []\n",
        "    for t in trigs:\n",
        "        try: wave_snip_list.append(waveform[t+window_tics])\n",
        "        except: None\n",
        "    wave_snip_stack = np.stack(wave_snip_list,axis=-1)\n",
        "    return wave_snip_stack, window_time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def event_properties(waveform,trigs,fs=1000,window_ms=[-150,150]):\n",
        "    wave_snip_stack, window_time = get_waveforms_stack(waveform,trigs,fs,window_ms=[-150,150])\n",
        "    waveform_hilb_env = np.abs(scipy.signal.hilbert(waveform))\n",
        "    wave_snip_stack_hilb, window_time = get_waveforms_stack(waveform_hilb_env,trigs,fs,window_ms=[-150,150])\n",
        "    waveform_z_power = z_trans(waveform_hilb_env)\n",
        "\n",
        "    events_df = pd.DataFrame(index=np.arange(wave_snip_stack.shape[1]))\n",
        "    events_df['trig_ind'] = trigs\n",
        "    events_df['trig_time'] = trigs/fs\n",
        "    events_df['peak_amp'] = np.max(wave_snip_stack,axis=0)\n",
        "    events_df['min_amp'] = np.min(wave_snip_stack,axis=0)\n",
        "    events_df['tot_hilb'] = np.sum(wave_snip_stack_hilb,axis=0)\n",
        "    events_df['peak_z_power'] = np.max(waveform_z_power,axis=0)\n",
        "    return events_df\n",
        "\n",
        "\n",
        "# display( event_properties(waveform,trigs).head(20))"
      ],
      "metadata": {
        "id": "vU3E6ItCLWaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "band = 'slow_gamma_band'\n",
        "\n",
        "waveform = filtered[band]['lfp']\n",
        "time = filtered['time_1khz']\n",
        "fig,ax = inspect_trace(waveform,time,z_scale=9,single_trace_plot_size=[10,2],spec_color='k')\n",
        "figax_prev= [fig,ax.twinx()]\n",
        "inspect_trace(filtered[band]['hilb_env'],time,z_scale=9,single_trace_plot_size=[10,2],figax_prev=figax_prev,spec_color='r')\n",
        "# for a in z[ax, ax2]:\n",
        "ax.set_xlim(0,3)\n",
        "ax.grid(visible=True, which='both', axis='both')\n"
      ],
      "metadata": {
        "id": "TVUU1We3OkFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def summarize_trigs(filtered,trig_bands,window_ms=[-120,120]):\n",
        "    fig,ax = plt.subplots(3,3,figsize=[10,10])\n",
        "    for b in trig_bands:\n",
        "        bi = trig_bands.index(b)\n",
        "        trigs = filtered[b]['trigs']\n",
        "        for bb in trig_bands:\n",
        "            bbi = trig_bands.index(bb)\n",
        "            waveform = filtered[bb]['lfp']\n",
        "            fs = filtered['fs']\n",
        "            wave_snip_stack,window_time = get_waveforms_stack(waveform,trigs,fs,window_ms=window_ms)\n",
        "            ax[bi,bbi].plot(window_time, wave_snip_stack,'grey')\n",
        "            ax[bi,bbi].plot(window_time, np.mean(wave_snip_stack,1),'r')\n",
        "            ax[bi,bbi].set_title(f'{bb} \\n triggered from \\n {b}')\n",
        "# summarize_trigs(filtered,trig_bands,window_ms=[-120,120])\n",
        "# plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "J-4zJ-remRwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #### Abundance over Time #######\n",
        "# bin_wid =15\n",
        "\n",
        "# for f in rip_df.index:\n",
        "#     fig,ax=plt.subplots(3,figsize=(16,6))\n",
        "#     fig.suptitle(os.path.basename(f))\n",
        "#     for ch in chan_list:\n",
        "#         filtered = rip_df.loc[f,ch]\n",
        "#         for b in trig_bands:\n",
        "#             ai = trig_bands.index(b)\n",
        "#             trigs = filtered[b]['trigs']\n",
        "#             time_1khz = filtered['time_1khz']\n",
        "#             ep_0_inds =  rip_df.loc[f,'ep_0_inds']\n",
        "#             epoch_time = time_1khz - time_1khz[ep_0_inds[-1]]\n",
        "#             bottom_epo_time = np.floor(np.min(epoch_time)/bin_wid)*bin_wid\n",
        "#             top_epo_time = np.ceil(np.max(epoch_time)/bin_wid)*bin_wid\n",
        "#             bins = np.arange(bottom_epo_time,top_epo_time ,bin_wid)\n",
        "#             t_hist,bin_edges = np.histogram(epoch_time[trigs], bins=bins)\n",
        "#             numt = len(trigs)\n",
        "#             # ax.bar(bin_edges[:-1],t_hist/bin_wid,label=f\"{b}_{ch} ({numt})\",width=8,)\n",
        "#             ax[ai].plot(bin_edges[:-1],t_hist/bin_wid,'-o',label=f\"{b}_{ch} ({numt})\",)\n",
        "#             ax[ai].legend(loc='upper left',bbox_to_anchor=(1, 1, 1, 0))\n",
        "\n"
      ],
      "metadata": {
        "id": "BpLR8PPJXJZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# abf = pyabf.ABF('/content/Bumet_ephys_data/2023x07x06_E3KI_F_P525_s3x4_0000.abf')\n",
        "# freq_bands = time_bands(abf,sweepNumber=0,channel=0)\n",
        "\n",
        "\n",
        "def plot_abund_ts(time_1khz,trigs,bin_wid=10):\n",
        "    fig,ax=plt.subplots(1,figsize=(16,4))\n",
        "    bins = np.arange(0,np.max(time_1khz)+bin_wid,bin_wid)\n",
        "    hist,edges = np.histogram(time_1khz[trigs], bins=bins)\n",
        "    ax.bar(bins[1:],hist/bin_wid,width=bin_wid)\n",
        "    ax.set_ylabel('SW abundance (Hz)')\n",
        "    plt.show()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "# trigs_alligned, fig, ax = get_SW_trig_inds(sharp_wave_band,fs,sw_thresh=-4,to_plot=True)"
      ],
      "metadata": {
        "id": "16O8obWIcFCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pL-RXGFYJInL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # from scipy import signal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# fs = 10000\n",
        "# w = 6.\n",
        "# top_freq = fs/2\n",
        "# top_freq = 600\n",
        "# freq = np.linspace(1, top_freq, 100)\n",
        "# freq = np.logspace(np.log2(10), np.log2(top_freq), num=40, endpoint=True, base=2)\n",
        "# widths = w*fs / (2*freq*np.pi)\n",
        "# cwtm = scipy.signal.cwt(in0, scipy.signal.morlet2, widths, w=w)\n",
        "\n",
        "# cw_abs = np.abs(cwtm)\n",
        "# cw_mean = np.expand_dims(np.mean(cw_abs,axis=1),-1)\n",
        "# cw_std = np.expand_dims(np.std(cw_abs,axis=1),-1)\n",
        "# cw_z = (cw_abs - cw_mean) / cw_std\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GcBKr3jlMwh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dR5haUftSOwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\" Parse Epochs \"\"\"\n",
        "# rip_df['ep_0_inds'] = np.nan\n",
        "# rip_df['ep_1_inds'] = np.nan\n",
        "# rip_df['ep_0_inds'] = rip_df['ep_0_inds'].astype(object)\n",
        "# rip_df['ep_1_inds'] = rip_df['ep_1_inds'].astype(object)\n",
        "\n",
        "# for f in rip_df.index:\n",
        "\n",
        "#     # get actual times\n",
        "#     epoch_0_tag = rip_df.loc[f,'epoch_0']\n",
        "#     epoch_0_time = epoch_0_tag.split(' ')[1]\n",
        "#     if ':' in epoch_0_time: int(epoch_0_time.split(':')[0]*60 + epoch_0_time.split(':')[1] )\n",
        "#     epoch_1_tag = rip_df.loc[f,'epoch_1']\n",
        "#     if not isinstance(epoch_1_tag,str):\n",
        "#          epoch_1_time = np.nan\n",
        "#     else:\n",
        "#         epoch_1_time = epoch_1_tag.split(' ')[1]\n",
        "#         if ':' in epoch_1_time:\n",
        "#             epoch_1_time =  int( epoch_1_time.split(':')[0])*60 + int(epoch_1_time.split(':')[1] )\n",
        "\n",
        "#     # epoch indicies\n",
        "#     fs = rip_df.at[f,'ch0']['fs']\n",
        "#     time = rip_df.at[f,'ch0']['time_1khz']\n",
        "#     if np.isnan(epoch_1_time):\n",
        "#         rip_df.at[f,'ep_0_inds'] = np.arange(0,len(time))\n",
        "#     else:\n",
        "#         rip_df.at[f,'ep_0_inds'] = np.arange(0, epoch_1_time*fs)\n",
        "#         rip_df.at[f,'ep_1_inds'] = np.arange(epoch_1_time*fs,len(time))\n",
        "# display(rip_df.head(5))"
      ],
      "metadata": {
        "id": "MgzWOQgbV1Dt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkP23Vz986GqjGfjxG1Rxk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Workshop/blob/main/PatchSeq_Pilot_scAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas\n",
        "# !pip install scanpy\n",
        "# !pip install wget\n"
      ],
      "metadata": {
        "id": "wVstx1LNjjww"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JuH4Rr39gtC5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import os\n",
        "import wget\n",
        "import gzip\n",
        "import shutil\n",
        "import chardet\n",
        "import matplotlib.pyplot as plt\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_anndata(file_path):\n",
        "    \"\"\"\n",
        "    Load an AnnData object from the specified file path.\n",
        "    \"\"\"\n",
        "    adata = sc.read(file_path)\n",
        "    return adata\n"
      ],
      "metadata": {
        "id": "h75klc4bWZxH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_decompress_gtf(gtf_url, gtf_file):\n",
        "    \"\"\"\n",
        "    Download the GTF file and decompress it, if not already done.\n",
        "\n",
        "    Parameters:\n",
        "    gtf_url (str): The URL to download the GTF file from.\n",
        "    gtf_file (str): The path where the GTF file (compressed) will be saved.\n",
        "\n",
        "    Returns:\n",
        "    str: The path to the decompressed GTF file.\n",
        "    \"\"\"\n",
        "    # Define the decompressed file path\n",
        "    decompressed_file = gtf_file.replace('.gz', '')\n",
        "\n",
        "    # Check if the decompressed file already exists\n",
        "    if not os.path.isfile(decompressed_file):\n",
        "        # Check if the compressed file already exists\n",
        "        if not os.path.isfile(gtf_file):\n",
        "            # Download the GTF file\n",
        "            wget.download(gtf_url, gtf_file, bar=None)  # `bar=None` to suppress the download progress bar\n",
        "\n",
        "        # Decompress the GTF file\n",
        "        with gzip.open(gtf_file, 'rb') as f_in:\n",
        "            with open(decompressed_file, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    else:\n",
        "        print(f\"{decompressed_file} already exists. Skipping download and decompression.\")\n",
        "\n",
        "    return decompressed_file\n",
        "\n",
        "\n",
        "def detect_file_encoding(file_path):\n",
        "    \"\"\"\n",
        "    Detect the encoding of a file using chardet.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        result = chardet.detect(file.read(10000))\n",
        "    return result['encoding']\n",
        "\n",
        "def create_ensembl_to_gene_mapping(gtf_file):\n",
        "    \"\"\"\n",
        "    Create a mapping of Ensembl IDs to gene names from a GTF file, focusing only on coding regions (exons).\n",
        "    \"\"\"\n",
        "    ensembl_to_gene = {}\n",
        "\n",
        "    with open(gtf_file, 'r', encoding='utf-8', errors='replace') as file:\n",
        "        for line in file:\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "            fields = line.strip().split('\\t')\n",
        "            if len(fields) < 9:\n",
        "                continue  # skip lines that do not have enough fields\n",
        "            seqname, source, feature, start, end, score, strand, frame, attributes = fields\n",
        "\n",
        "            if feature == 'exon':\n",
        "                # Extract attributes\n",
        "                attributes_dict = dict(item.split(None, 1) for item in attributes.split('; ') if item)\n",
        "                ensembl_id = attributes_dict.get('gene_id', '').strip('\"')\n",
        "                gene_name = attributes_dict.get('gene_name', '').strip('\"')\n",
        "\n",
        "                if ensembl_id and gene_name:\n",
        "                    ensembl_to_gene[ensembl_id.split('.')[0]] = gene_name\n",
        "\n",
        "    ensembl_df = pd.DataFrame(list(ensembl_to_gene.items()), columns=['Ensembl_ID', 'Gene_Name'])\n",
        "    ensembl_df.to_csv('ensembl_to_gene_mapping.csv', index=False)\n",
        "\n",
        "    return ensembl_to_gene, ensembl_df"
      ],
      "metadata": {
        "id": "VJ2zl6NXX_MB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_gene_names_metadata(adata, ensembl_to_gene):\n",
        "    \"\"\"\n",
        "    Add gene names as metadata to the AnnData object.\n",
        "    \"\"\"\n",
        "    gene_names = [ensembl_to_gene.get(gene_id, 'unknown') for gene_id in adata.var_names]\n",
        "    adata.var['gene_name'] = gene_names\n",
        "    return adata"
      ],
      "metadata": {
        "id": "Ji9CJMTWWfyL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_coding_genes(csv_file):\n",
        "    \"\"\"\n",
        "    Load coding genes from a CSV file and return a set of gene names.\n",
        "    \"\"\"\n",
        "    coding_df = pd.read_csv(csv_file)\n",
        "    coding_genes = set(coding_df[coding_df['is_coding'] == True]['external_gene_name'])\n",
        "    return coding_genes"
      ],
      "metadata": {
        "id": "-0d30RCoWg5Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_noncoding_genes(adata, coding_genes):\n",
        "    \"\"\"\n",
        "    Filter out non-coding genes from the AnnData object.\n",
        "    \"\"\"\n",
        "    is_coding = adata.var['gene_name'].isin(coding_genes)\n",
        "    filtered_adata = adata[:, is_coding].copy()\n",
        "    return filtered_adata"
      ],
      "metadata": {
        "id": "kGVIiU94Wjo7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consolidate_counts_by_gene(adata):\n",
        "    \"\"\"\n",
        "    Consolidate counts for genes by summing counts for identical gene names.\n",
        "    \"\"\"\n",
        "    # Convert AnnData to DataFrame\n",
        "    counts_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var['gene_name'])\n",
        "\n",
        "    # Consolidate counts by gene\n",
        "    # Group by gene names (columns), summing counts for each gene\n",
        "    consolidated_df = counts_df.groupby(counts_df.columns, axis=1).sum()\n",
        "\n",
        "    # Ensure the new DataFrame has the same index and columns\n",
        "    consolidated_df = consolidated_df.groupby(consolidated_df.index).sum()\n",
        "\n",
        "    # Create a new AnnData object with consolidated counts\n",
        "    # The new var DataFrame should have gene names as its index\n",
        "    adata_consolidated = sc.AnnData(\n",
        "        X=consolidated_df.values,\n",
        "        obs=adata.obs,\n",
        "        var=pd.DataFrame(index=consolidated_df.columns)\n",
        "    )\n",
        "\n",
        "    return adata_consolidated"
      ],
      "metadata": {
        "id": "x7rgrJBvWlmo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your files\n",
        "os.chdir(r'D:\\Dropbox (Gladstone)\\Gladstone Dropbox\\Dennis Tabuena\\0_Projects\\_ApoE Patch Seq\\pilot_patchseq\\analysis_workspace')\n",
        "counts_file = r\"D:\\Dropbox (Gladstone)\\Gladstone Dropbox\\Dennis Tabuena\\0_Projects\\_ApoE Patch Seq\\pilot_patchseq\\counts.STAR.MOUSE.txt\"\n",
        "\n",
        "# Define paths and URLs for the GTF file\n",
        "gtf_url = 'ftp://ftp.ensembl.org/pub/release-110/gtf/mus_musculus/Mus_musculus.GRCm39.110.gtf.gz'\n",
        "gtf_file = 'Mus_musculus.GRCm39.110.gtf.gz'\n",
        "\n",
        "# Decompress and create the Ensembl to Gene mapping\n",
        "decompressed_file = download_and_decompress_gtf(gtf_url, gtf_file)\n",
        "\n",
        "# Load the AnnData object\n",
        "patchseq_pilot_df = pd.read_csv(counts_file, sep='\\t', index_col=0)\n",
        "patchseq_pilotadata = sc.AnnData(X=patchseq_pilot_df.values,\n",
        "                   obs=pd.DataFrame(index=patchseq_pilot_df.index),\n",
        "                   var=pd.DataFrame(index=patchseq_pilot_df.columns)).T\n",
        "\n",
        "# Get Ensembl to Gene mapping\n",
        "ensembl_to_gene, df = create_ensembl_to_gene_mapping(decompressed_file)\n",
        "# display(df)\n",
        "\n",
        "# Add gene names as metadata\n",
        "patchseq_pilotadata = add_gene_names_metadata(patchseq_pilotadata, ensembl_to_gene)\n",
        "\n",
        "# Load coding genes\n",
        "coding_genes_csv = 'mmusculus_coding_noncoding.csv'\n",
        "coding_genes = load_coding_genes(coding_genes_csv)\n",
        "# display(coding_genes)\n",
        "\n",
        "# Filter out non-coding genes\n",
        "patchseq_pilotadata_filt= filter_noncoding_genes(patchseq_pilotadata, coding_genes)\n",
        "display(patchseq_pilotadata_filt)\n",
        "\n",
        "# Consolidate counts by gene\n",
        "consolidated_adata_cons = consolidate_counts_by_gene(patchseq_pilotadata_filt)\n",
        "display(consolidated_adata_cons)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "3abrJAsKWnr3",
        "outputId": "56f1ad9b-413c-447f-eaa8-7b99c8025b84"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mus_musculus.GRCm39.110.gtf already exists. Skipping download and decompression.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AnnData object with n_obs × n_vars = 24 × 21470\n",
              "    var: 'gene_name'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\denni\\AppData\\Local\\Temp\\ipykernel_1788\\2063635859.py:10: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
            "  consolidated_df = counts_df.groupby(counts_df.columns, axis=1).sum()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AnnData object with n_obs × n_vars = 24 × 21446"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}